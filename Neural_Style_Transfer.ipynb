{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Neural Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nayankote/Neural-Style-Transfer/blob/master/Neural_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blCxGp86Fck9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import pprint\n",
        "from PIL import Image\n",
        "from tensorflow.python.framework import ops\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-uQe9VSFclC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class config:\n",
        "    \n",
        "    image_width = 800\n",
        "    image_height = 600\n",
        "    color_channels = 3\n",
        "    noise_ratio = 0.6\n",
        "    means = np.array([123.68, 116.779, 103.999]).reshape((1,1,1,3)) \n",
        "    #this is the mean RGB value of the pictures in the imagenet data\n",
        "    #surprisingly(or not) a mud greyish brown is the most common color\n",
        " \n",
        "    model = \"/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/imagenet-vgg-verydeep-19.mat\"\n",
        "    style_image = '/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/monet.jpg'\n",
        "    content_image = '/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/louvre.jpg'\n",
        "\n",
        "    #These are the weights given to each layer for the style error calculation, try changing them. \n",
        "    style_layers = [    \n",
        "    ('conv1_1', 0.2),\n",
        "    ('conv2_1', 0.2),\n",
        "    ('conv3_1', 0.2),\n",
        "    ('conv4_1', 0.2),\n",
        "    ('conv5_1', 0.2)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BYmFqyXFclI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vgg_model():\n",
        "    \n",
        "    model_load = scipy.io.loadmat(\"/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/imagenet-vgg-verydeep-19.mat\")\n",
        "    model_layers = model_load['layers']\n",
        "    \n",
        "    def _weights(layer, expected_layer_name):\n",
        "        wb = model_layers[0][layer][0][0][2] \n",
        "        W = wb[0][0]\n",
        "        b = wb[0][1]\n",
        "        layer_name = model_layers[0][layer][0][0][0]\n",
        "        assert layer_name == expected_layer_name\n",
        "        return W,b\n",
        "        \n",
        "    def _conv2d(prev_layer, layer, layer_name):\n",
        "        W,b = _weights(layer,layer_name)\n",
        "        W = tf.constant(W)\n",
        "        b = tf.constant(np.reshape(b, (b.size)))\n",
        "        return tf.nn.conv2d(prev_layer, filters = W, strides = [1,1,1,1], padding = 'SAME') + b\n",
        "    \n",
        "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
        "        return tf.nn.relu(_conv2d(prev_layer, layer, layer_name))\n",
        "    \n",
        "    def _pool(prev_layer, pooltype = 'avg'):\n",
        "        if pooltype == 'avg':\n",
        "            return tf.nn.avg_pool(prev_layer, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
        "        else : \n",
        "            return tf.nn.max_pool(prev_layer, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
        "    \n",
        "    graph = {}\n",
        "    graph['input']   = tf.Variable(np.zeros((1, config.image_height, config.image_width, config.color_channels)), dtype = 'float32')\n",
        "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
        "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
        "    graph['avgpool1'] = _pool(graph['conv1_2'])\n",
        "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
        "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
        "    graph['avgpool2'] = _pool(graph['conv2_2'])\n",
        "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
        "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
        "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
        "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
        "    graph['avgpool3'] = _pool(graph['conv3_4'])\n",
        "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
        "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
        "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
        "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
        "    graph['avgpool4'] = _pool(graph['conv4_4'])\n",
        "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
        "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
        "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
        "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
        "    graph['avgpool5'] = _pool(graph['conv5_4'])\n",
        "    \n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U35bTX3NzvgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(img):\n",
        "    \n",
        "    return img.resize((config.image_width,config.image_height), Image.ANTIALIAS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05cepRokFclN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_noise_image(content_image, noise_ratio = config.noise_ratio):\n",
        "    \n",
        "    noise_image = np.random.uniform(-100, 100, (1, config.image_height, config.image_width, config.color_channels)).astype('float32') \n",
        "    #check what happens with np.random.randn and changing +- 20\n",
        "    \n",
        "    input_image = noise_ratio*noise_image + (1-noise_ratio)*content_image \n",
        "    #check what happens when noise ratio changes\n",
        "    \n",
        "    return input_image "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pIu6gcFclR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_and_normalize_image(image):\n",
        "    \n",
        "    image = np.reshape(image, ((1,) + image.shape)) #required input shape for vgg19\n",
        "\n",
        "    image = image - config.means\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61BR99bZFclT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_image(path, image):\n",
        "    \n",
        "    image = image + config.means\n",
        "    \n",
        "    image = np.clip(image[0],0,255).astype('uint8') \n",
        "    #changes values >255 (or <0) to 255 (or 0)\n",
        "    \n",
        "    imageio.imwrite(path, image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40X-tXnkFclV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cost computation\n",
        "def content_cost(a_C,a_G):\n",
        "    (m, n_H, n_W, n_C) = a_G.get_shape().as_list()\n",
        "    \n",
        "    #a_C and a_G are unrolled from (m x n_H x n_W x n_C) to (m x (n_h*n_W) x n_C) \n",
        "    a_C_unrolled = tf.reshape(tf.transpose(a_C, perm = [0,3,1,2]), shape = [m,-1,n_C])\n",
        "    a_G_unrolled = tf.reshape(tf.transpose(a_G, perm = [0,3,1,2]), shape = [m,-1,n_C])\n",
        "    \n",
        "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C,a_G)))/(4*n_H*n_W*n_C)\n",
        "    \n",
        "    return J_content\n",
        "\n",
        "def gram_matrix(img):\n",
        "    \n",
        "    return tf.matmul(img,tf.transpose(img))\n",
        "\n",
        "def style_cost_layer(a_S,a_G):\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    #a_S and a_G are unrolled from (m x n_H x n_W x n_C) to (n_C x (n_H*n_W)) [m = 1]  \n",
        "    a_S_unrolled = tf.reshape(tf.transpose(a_S, perm = [0,3,1,2]), shape = [n_C,-1])\n",
        "    a_G_unrolled = tf.reshape(tf.transpose(a_G, perm = [0,3,1,2]), shape = [n_C,-1])\n",
        "    \n",
        "    gram_a_S = gram_matrix(a_S_unrolled)\n",
        "    gram_a_G = gram_matrix(a_G_unrolled)\n",
        "    \n",
        "    J_style_layer = tf.reduce_sum(tf.reduce_sum(tf.square(tf.subtract(gram_a_S, gram_a_G))))/((2*n_H*n_W*n_C)**2)\n",
        "    \n",
        "    return J_style_layer\n",
        "\n",
        "def total_style_cost(model, layers = config.style_layers):\n",
        "    \n",
        "    J_style = 0\n",
        "    \n",
        "    for layer_name, coeff in layers:\n",
        "        out = model[layer_name]\n",
        "        \n",
        "        a_S = sess.run(out)\n",
        "        \n",
        "        a_G = out\n",
        "        \n",
        "        J_style += coeff*style_cost_layer(a_S,a_G)\n",
        "    \n",
        "    return J_style\n",
        "\n",
        "def total_cost(J_content, J_style, alpha = 10, beta = 40): #mess around with the weights\n",
        "    \n",
        "        return alpha*J_content + beta*J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRf0irABFclX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset the graph\n",
        "ops.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPuyyeYeFclY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading images \n",
        "content_image = Image.open(config.content_image)\n",
        "content_image = np.array(resize_image(content_image))\n",
        "content_image = reshape_and_normalize_image(content_image)\n",
        "style_image = Image.open(config.style_image)\n",
        "style_image = np.array(resize_image(style_image))\n",
        "style_image = reshape_and_normalize_image(style_image)\n",
        "generated_image = generate_noise_image(content_image)\n",
        "imshow(generated_image[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kMdydJkFcld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading model \n",
        "model = load_vgg_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gcI1rOEFclf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.compat.v1.Session() as sess : \n",
        "    sess.run(model['input'].assign(content_image))\n",
        "    out = model['conv4_2']\n",
        "    a_C = sess.run(out)\n",
        "    a_G = out\n",
        "    J_content = content_cost(a_C,a_G)\n",
        "    \n",
        "    sess.run(model['input'].assign(style_image))\n",
        "    J_style = total_style_cost(model,config.style_layers)\n",
        "    \n",
        "    #mess around with these weights\n",
        "    J = total_cost(J_content,J_style,10,40)\n",
        "    \n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(2)\n",
        "    train_step = optimizer.minimize(J)\n",
        "    \n",
        "    def model_nn(sess, input_image, num_iterations = 1000):\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        \n",
        "        sess.run(model['input'].assign(input_image))\n",
        "        \n",
        "        for i in range(num_iterations):\n",
        "            sess.run(train_step)\n",
        "            \n",
        "            generated_image = sess.run(model['input'])\n",
        "            \n",
        "            if i%200 == 0 :\n",
        "                Jt,Jc,Js = sess.run([J, J_content, J_style])\n",
        "                print(\"Iteration \"+str(i) +\":\")\n",
        "                print(\"total cost = \"+str(Jt))\n",
        "                print(\"content cost = \"+str(Jc))\n",
        "                print(\"style cost = \"+str(Js))\n",
        "                save_image(\"/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/\"+str(i) +\".png\",generated_image)\n",
        "            \n",
        "        save_image('/content/gdrive/My Drive/Colab Notebooks/Neural Style Transfer/generated_image_final.jpg',generated_image)\n",
        "        \n",
        "        return generated_image\n",
        "    \n",
        "    model_nn(sess, generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}